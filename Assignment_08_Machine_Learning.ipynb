{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782b8c04-2340-40e5-80e1-2040526f1a08",
   "metadata": {},
   "source": [
    "# Assignment 8: Machine Learning\n",
    "Please submit this assignment to Canvas as a jupyter notebook (.ipynb).  The assignment will introduce you to machine learning techniques used in the analysis of EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc4275c-59b0-46c1-a169-3ffba2293ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmlreaders as cml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d82cb-55c5-4ac3-a1dc-07b31423f516",
   "metadata": {},
   "source": [
    "This assignment is designed to familiarize you with multivariate analysis of intracranial EEG data. For each subject, you will train a logistic-regression classifier to discriminate subsequently recalled vs non-recalled studied items using the distribution of spectral power across electrodes as the features. After completing the assignment you should be able to fit an L2-penalized logistic regression classifier to intracranial electrophysiological recordings. You should also be able to construct a receiver operating characteristic (ROC) curve and compute area under the curve (AUC) to assess classifier performance, and compare train and test performance.\n",
    "\n",
    "You will use data from the following 20 FR1/catFR1 subjects in the intracranial EEG (iEEG) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274fa166-101c-43b6-8121-e7c7e224912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "subs_FR = ['R1380D', 'R1111M', 'R1332M', 'R1377M', 'R1065J', 'R1385E', 'R1189M', \\\n",
    "           'R1108J', 'R1390M', 'R1236J', 'R1391T', 'R1401J', 'R1361C', 'R1060M', \\\n",
    "           'R1350D', 'R1378T', 'R1375C', 'R1383J', 'R1354E', 'R1292E']\n",
    "print(len(subs_FR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8346877-62bc-4aaf-aed0-e98177874472",
   "metadata": {},
   "source": [
    "For each of these subjects, use the following processing steps:\n",
    "* Load EEG with CMLReader.load_eeg from a bipolar montage loaded using CMLReader.load('pairs').\n",
    "* Apply a Butterworth notch filter around 60 Hz (freqs = [58 62]) when extracting the voltage.\n",
    "* Calculate power at the above frequencies with a Morlet wavelet with wavenumber (keyword “width”) of 6 for each encoding event (from time 0 until 1.6 seconds after the encoding event onset) using a 1 second buffer.\n",
    "* For each frequency, channel, and encoding event, average the power over the entire 1600 ms encoding period (but not over the buffer period!)\n",
    "* Log-transform the average encoding power values as in the final step of the previous problem.\n",
    "* In some cases you may notice artifacts in the data that manifest in power values of zero. These would produce problems in the transformation and classification, so please exclude any events with this issue from all analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4a234-5a61-4cda-acce-826cbef5db90",
   "metadata": {},
   "source": [
    "You will train an L2-penalized logistic regression classifier on the time-frequency (TF) data obtained during item encoding for every subject. Throughout this assignment, unless otherwise specified, we will use the default parameters for the *LogisticRegression* classifier in sklearn.\n",
    "\n",
    "## Question 1, Generate features: \n",
    "* For your input features, extract spectral power as in Assignment 2 with Morlet wavelets at 8 frequencies logarithmically spaced between 3 and 180 Hz (np.logspace(np.log10(3), np.log10(180),8)) for each recorded electrode pair (“channel”). Average the power across each of these frequencies over the 1600 ms word encoding period.\n",
    "* For each subject, create an $X_{N×p}$ matrix of spectral power patterns ($N$= number of encoding events concatenated across sessions; $p$ = number of frequencies × number of channels) and obtain the $y_{N×1}$ vector of labels (1: recalled, 0: non-recalled). The pair $(X, y)$ will be our dataset.\n",
    "* Z-score the features across observations (i.e., events) within each session. Since we're performing leave-one-session-out cross validation in this assignment, z-scoring within-session prevents information from leaking between train sessions and test sessions through the z-score statistics.\n",
    "* Some subjects will have different sets of electrodes for different recording sessions. For these subjects you can drop the sessions such that you keep the largest possible set of available sessions which all have the same recording contacts (there could be groups of sessions for the same subject with different electrode sets). The reasons a subject might have different active recording electrodes across sessions are:\n",
    "    * some subjects have so many electrodes implanted that not all of them could be recorded from simultaneously; these subjects will sometimes then have different \"montages\" in which different electrodes are turned connected or disconnected or\n",
    "    * some subjects have multiple implant surgeries, with different electrodes being in place after each operation, meaning again that the same subject will have different sets of electrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2d2a83-46ab-4aa4-88dd-89357b739339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d2795-a3ce-4dc9-b0cf-cb50457a17fe",
   "metadata": {},
   "source": [
    "## Question 2, Cross-validation:\n",
    "* Use leave-one-session-out cross-validation to train and test L2-penalized logistic regression classifiers. This means that for each cross-validation iteration, you will (1) leave out one session ($X_{test}$, $y_{test}$), (2) train the model on the other sessions ($X_{train}$, $y_{train}$), and (3) test the trained model on the held-out session. Repeat this procedure by iterating across all sessions that a subject has. For each iteration of the cross-validation procedure, you will train the L2-penalized logistic regression classifier on the encoding events from all sessions except the held-out session. You will take the model fit to this training set and use it to predict recall performance for the encoding events in the held-out session. For each encoding event in the held out session, you should get a predicted probability that this item will be subsequently recalled. Once you have held out each session (i.e., at the end of the leave-one-session-out cross-validation procedure), you will have the predicted probability for each encoding event (all predicted by models trained on all encoding events except for the ones in the same session). After doing the above separately for each subject, you should now have cross-validated predictions for all encoding events. Use the default penalty parameter (C) of 1.0 (you will optimize this parameter for some subjects in Part 2). \n",
    "* For the first three subjects in the list above, plot a histogram of the predicted cross-validated probabilities across all encoding events, giving different colors to predictions for encoding events of words that were subsequently recalled and for encoding events for words that were not recalled. How strongly do the neural features predict subsequent recall?\n",
    "* Hint: since different sessions have different numbers of events (subjects can discontinue a session partway through), you'll need to implement leave-one-session-out cross validation without using the KFold sklearn class used in the examples from the intro material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc43a8f2-7ddc-4ca0-827c-b64e69e47252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354c848-b7b4-407e-9827-0cdefb44b6ff",
   "metadata": {},
   "source": [
    "## Question 3, Construct across-subject ROCs and AUCs using sklearn functions:\n",
    "* To assess the performance of a classifier, we will utilize the area under the receiver operating curve (AUC). Using sklearn’s ROC curve function, calculate the ROC and the corresponding AUC for each subject. Plot all the subjects’ ROC curves in one plot, and plot all the subjects’ AUCs in one histogram. To compute a subject-level ROC curve and AUC value, pool all predictions across the outer cross-validation folds and compute the AUC/ROC curve with the pooled predictions.\n",
    "* How good is the performance? Run a statistical test to determine if the between-subject average performance is reliably above chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31d604e-c6fb-4faa-8266-0e89b914a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd77b0-16c3-46f9-b811-595c264cfcb3",
   "metadata": {},
   "source": [
    "## Question 4, Train and Test AUCs\n",
    "Report mean train AUCs and mean test AUCs across cross validation folds for all subjects with two overlapping histograms (two histograms in the same plot). In comparison to how the test AUCs were computed at the subject level in previous problems, you can compute the train and test AUCs for a given outer fold with just the predictions from that fold; then you can average those fold-level AUCs together.\n",
    "* What is the mean difference across subjects in cross-validated AUC scores between training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d718c7e0-e82a-4c0a-a9c3-de72bcddf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_311",
   "language": "python",
   "name": "workshop_311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
