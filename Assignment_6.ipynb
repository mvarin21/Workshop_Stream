{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c466fdb-8e50-4ae5-8aa3-313459f88793",
   "metadata": {},
   "source": [
    "# Assignment 6: Signal Processing and Spectral Analysis\n",
    "Please submit this assignment to Canvas as a jupyter notebook (.ipynb).  The assignment will have you do spectral analysis of EEG timeseries data using scalp EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617772bf-1e7e-4bf8-8623-0d69ef8257ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import mne\n",
    "import ptsa\n",
    "import cmlreaders as cml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ptsa.data.filters import morlet\n",
    "from ptsa.data.filters import ButterworthFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ecf955-d3b2-4122-95f3-e8150bf22512",
   "metadata": {},
   "source": [
    "## Assignment Overview\n",
    "\n",
    "In this project you will analyze a multi-session free recall experiment to determine the spectral biomarkers of successful memory encoding. To determine differences in brain activity (EEG signals) that predict whether a studied item will be subsequently remembered (recalled) you will compare two classes of events: word encodings that led to later recall and those that did not.  This assignment will ask you to analyze data from the ltpFR2 dataset (Kahana et al., 2018, JEP:LMC).  You will not analyze the entire dataset; rather, you will analyze a significant subset of subjects, specifically those listed as 'scalp_subs' below. \n",
    "\n",
    "All analyses in this project should include the following data processing steps unless the question explicitly instructs you to do otherwise:\n",
    "1. For scalp EEG data, use LCF “cleaned” data.\n",
    "2. After loading the data, apply a Butterworth notch filter around 60 Hz (freqs = [58-62]) to remove line noise.\n",
    "3. Include a 1000 ms buffer around time period of interest when computing power; compute power using raw voltage at the original sampling rate.\n",
    "4. All logarithms referenced in this assignment are base-10 logarithms (e.g., np.log10, not np.log, which is the natural log)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f14171-96bb-416b-b98b-6ce2c3132640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these subjects for problems other than 1 and 2\n",
    "scalp_subs = ['LTP093', 'LTP117', 'LTP123', 'LTP133', 'LTP228', \n",
    "              'LTP246', 'LTP249', 'LTP251', 'LTP258', 'LTP259', \n",
    "              'LTP265', 'LTP269', 'LTP279', 'LTP280', 'LTP285', \n",
    "              'LTP287', 'LTP293', 'LTP296', 'LTP297', 'LTP302', \n",
    "              'LTP304', 'LTP307', 'LTP310', 'LTP311', 'LTP317', \n",
    "              'LTP318', 'LTP322', 'LTP327', 'LTP329', 'LTP330']\n",
    "\n",
    "# use these for Problems 1 to 2\n",
    "scalp_3subs = scalp_subs[0:3]\n",
    "\n",
    "freqs = np.unique(np.round(np.logspace(np.log10(1), np.log10(300), 17)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bcd4a-c18e-4411-b6ba-fc13da424585",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "1. Load data from the three subjects in 'scalp_3subs'. For each subject, first extract the behavioral data and report basic descriptive statistics including number of sessions completed, number of lists per session, and average percentage of correctly recalled items. Report these data separately for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f36365-c1dc-43ca-ba3e-3930274e6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966748e-1f9a-479c-949e-ecad5b022c88",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "1) For each of the three initial subjects you will compute a power spectrum (frequency on the x-axis, power on the y-axis) for recalled and non-recalled items. Thus, the goal is to report three graphs (one for each subject) with line plots indicating recalled events (red) and non-recalled events (blue). To do this, \n",
    "* Load all encoding events (irrespective of recall status). \n",
    "* Extract the LCF-corrected EEG signal for electrode E53 (left parietal lobe) including a buffer of 1000 ms on either side of the event\n",
    "    * Here we will define the encoding event as the 1600 ms interval that the word was displayed on the screen, from onset to offset. The buffer should extend before and after this period of time.\n",
    "    * For scalp data, contacts are not available from reader.load(’contacts’), so you will need to use reader.load eeg(...) followed by to_ptsa() on the result, and looking at the .channel.values attribute to obtain the channels.\n",
    "* Filter out line noise with the PTSA Butterworth filter (see examples from assignment 5). \n",
    "* Check that the EEG data match the number of trials in the behavioral data. \n",
    "* Compute the power spectrum with a wavelet transform with wavenumber 6 at the following 16 approximately logarithmically-spaced frequencies (in Hz): 1, 2, 3, 4, 6, 8, 12, 17, 25, 35, 50, 72, 103, 147, 210, 300. These freuencies are defined above in the 'freqs' variable.\n",
    "* For each subject, plot the log of power vs. frequency on a semi-log-x plot averaged across the encoding time interval and across events, separately for recalled and non-recalled events. Take the log of the subject-level averaged powers.\n",
    "\n",
    "2) What can we learn from the overall shape of the spectra and the qualitative (not statistical) differences between encoding conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e624a7-3593-42d3-84eb-4115f6173375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a25b0-18b0-4af3-8333-9257ce08a733",
   "metadata": {},
   "source": [
    "Question 2.2\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc281c1-6b02-4e7b-bc62-e7c0ef6f58e3",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "In this problem you will repeat the above analysis for all subjects in 'scalp_subs' and make some statistical inferences about spectral biomarkers of successful memory encoding.  \n",
    "* Be sure that your code is robust to exceptions that can be thrown by e.g. unavailable data, and if you have an exception in a particular session due to a problem with the data in that session, print or log the event so you can report it, and discard that session from the analysis. This data was all acquired with human participants across long stretches of time, and small things can go wrong.\n",
    "* Once you have verified your code, compute powers for all subjects as described above and create power spectra for recalled and non-recalled events.\n",
    "* Using the “cmldask” package you should be able to use a separate “core” on the cluster to process data from each session. Only run up to 5 jobs at once with up to 10 GB per job (or your jobs may be killed by mean-spirited admins). Make sure you save out the power values as you go (e.g. with the pickle library).\n",
    "\n",
    "1) Compute the average power spectra for each subject (separately for recalled and non-recalled items) and then take the log of that spectra. Averaging these power spectra across subjects, graph the average log-power spectra with 95% confidence bands (transparent light red and light blue shading, or your favorite clearly labeled color scheme).\n",
    "2) To get a sense for the effect of the log-transform and the semi-log plot, also produce plots without the log-transformation of the subject-level powers and ... \n",
    "3) ... also produce plots without either the log transformation or the semi-log plot.\n",
    "4) Plot the mean of the differences between the log spectra (recalled - ot recalled) computed separately for each subject (and then averaged across subjects) on a semi-log plot and place a confidence band on the mean difference score. \n",
    "5) What inferences can you now make from these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b2c7f0-3d7a-4aa0-959e-6768a2ea81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf0e865-4a88-4c27-9c03-1cc084c965d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.2\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c850126d-1bdb-4232-a5f5-67a0b39c8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.3\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a06814-61fd-46d9-91db-fbe65dfd06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.4\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f5449-8071-42f5-8b35-07d041fdc00b",
   "metadata": {},
   "source": [
    "Question 3.5\n",
    "\n",
    "**YOUR CODE HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc26d6-d1a6-4a04-939b-e66ec19044ab",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "In this problem, your goal is to assess the effects of two important processing steps on the analyses in the previous problem. Two common normalization procedures used in the analysis of brain signals are the log-transform, which attenuates extremely large values, and the z-transform, which allows you to normalize power values according to some baseline distribution. \n",
    "\n",
    "Here you will reproduce the analysis of the previous problem in computing between-subject differences of power spectra between recalled and not recalled items with each of these steps separately. The log-transform can be applied at different points in the analysis stream: immediately after computing power values, after averaging power values for each encoding interval, or after computing the z-transform of the power values. Similarly, the z-transformation can be done by normalizing to power (or log-power values) based on many choices of the “distribution” of power (or log-power values). If our goal is to normalize data to the distribution of power values across a given session, how do you define the “distribution” over which to estimate the standard deviation of values? Consider three different choices and assess the effects of these choices on your final analysis:\n",
    "\n",
    "1) Take the logarithm of power before averaging across time\n",
    "2) Z-score powers across the events within a session after averaging across time\n",
    "3) Complete a third transformation of your choice. \n",
    "4) Describe your motivation in considering the transform (in part 3).  Asses the effects of the different choices (parts 1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6618ba6a-95ad-47e6-b837-d397c59e2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bd3e533-a08d-4040-9980-f00465645857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4.2\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b3a2bb-4e38-426b-a5b4-8984e79e3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4.3\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060eb31-d814-4e67-969b-360fe2a78697",
   "metadata": {},
   "source": [
    "Question 4.4\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90b7da-0e3d-4c9a-be07-7327f9533fc5",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "All of the preceding analyses were conducted on a single scalp electrode. \n",
    "1) Repeat the analysis at all electrodes, generating a topographic map that shows the subsequent memory effect for the frequency 147 Hz. \n",
    "\n",
    "For this problem you should:\n",
    "* both log-transform your power values immediately after extracting them, and z-transform your data based on the distribution of values across each session (1–23) for each subject. \n",
    "* For the topographic maps, use a color bar to indicate the difference between power for recalled and non-recalled items. \n",
    "* Use the between-subject t-test method with Benjamini-Hochberg FDR correction to determine which electrodes in each map meet the p < 0.05 significance threshold. \n",
    "* Mark statistically significant electrodes on each topomap with some graphical element (star, dot, different color shading). \n",
    "\n",
    "2) Discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe50793-c16f-4602-9fa8-271bf7efc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc72455-13c7-405d-b5a7-264a31f941bc",
   "metadata": {},
   "source": [
    "Question 5.2\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bids",
   "language": "python",
   "name": "bids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
