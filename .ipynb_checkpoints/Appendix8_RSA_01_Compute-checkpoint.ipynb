{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894daffc-2455-4f52-bd82-c28e2f50a4ff",
   "metadata": {},
   "source": [
    "COGS 4290 RSA\n",
    "\n",
    "David Halpern 4/4/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8e8aa-1cbd-4d0b-9544-96cb75db4401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import cmlreaders as cml\n",
    "import cmldask.CMLDask as da\n",
    "import os\n",
    "import traceback\n",
    "from ptsa.data.filters import ResampleFilter, ButterworthFilter, MorletWaveletFilter\n",
    "from ptsa.data.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd64a74-26ef-41df-9233-a41dd63a5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = ['R1045E', 'R1102P', 'R1108J', 'R1141T', 'R1144E', 'R1157C',\n",
    "       'R1192C', 'R1202M', 'R1226D', 'R1236J', 'R1269E', 'R1277J',\n",
    "       'R1291M', 'R1310J', 'R1328E', 'R1330D', 'R1337E', 'R1351M',\n",
    "       'R1354E', 'R1361C', 'R1375C', 'R1383J', 'R1389J', 'R1390M',\n",
    "       'R1395M', 'R1401J', 'R1403N', 'R1412M', 'R1465D', 'R1468J',\n",
    "       'R1474T', 'R1476J', 'R1477J', 'R1482J', 'R1486J', 'R1490T',\n",
    "       'R1497T', 'R1501J', 'R1515T', 'R1525J', 'R1527J', 'R1530J',\n",
    "       'R1536J', 'R1541T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5939f2-ba47-40c8-a08d-48342f11964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = cml.get_data_index()\n",
    "exp = 'catFR1'\n",
    "exp_ix = ix.query('experiment == @exp and subject == @subs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ca8df-4872-4809-95bf-0354d18e9bce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48b5cf-79af-499e-aa48-23f04c6f9961",
   "metadata": {},
   "source": [
    "We first load the data and preprocess into power at different frequency bands both during encoding (300ms to 1300 ms after the word appears on screen) and right before retrieval (900 to 100ms before vocalization). In order to make signals comparable across encoding and retrieval, we standardize both of them by data from during the 10s countdown periods that preceded each list. This means that all of the data is relative to the countdown period (e.g. there is .5 standard deviations more power in the 3 Hz band than the average of the countdown period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701c4ee-195d-447a-a7bd-f8b5516322db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(row, \n",
    "                     settings_path='/home1/djhalp/ieeg_rsa/catFR1_test_encoding.pkl', \n",
    "                     save_path='/scratch/djh/rsa_class',\n",
    "                     overwrite=False):\n",
    "    \"\"\"\n",
    "    Compute log-transformed powers, averaged over time and stacked as (frequency, channel) to create features\n",
    "    These can later be normalized along the event axis.\n",
    "    \"\"\"\n",
    "    settings = da.Settings.Load(settings_path)\n",
    "    ix = cml.get_data_index()\n",
    "    #sub_ix = ix.query('experiment == @settings.experiment and subject == @subject')\n",
    "    ev_type = settings.type\n",
    "    save_fp = save_path + '/' + row.subject + '_' + str(row.session) + '_' + settings.type + '_feats.h5'\n",
    "    print(save_fp)\n",
    "    if (not os.path.exists(save_fp)) or overwrite:\n",
    "        print(\"Reading subject:\", row.subject, \"session:\", row.session)\n",
    "        # intialize data reader, load words events and buffered eeg epochs\n",
    "        r = cml.CMLReader(subject=row.subject, \n",
    "                          experiment=row.experiment, session=row.session,\n",
    "                          localization=row.localization, montage=row.montage)\n",
    "        \n",
    "        if settings.type == 'COUNTDOWN_START':\n",
    "            countdown_events = pd.read_csv(save_path+'/'+exp+'_countdown_evs.csv')\n",
    "            evs = countdown_events.query('subject == @row.subject and session == @row.session')\n",
    "        else:\n",
    "            evs = r.load('task_events')\n",
    "        evs = evs.query('type == @settings.type and eegoffset != -1')\n",
    "        evs = evs[evs['list'] > 0]\n",
    "        evs['category'] = evs['category'].str.lower()\n",
    "        print(evs)\n",
    "        scheme = r.load(\"pairs\")\n",
    "        if settings.type == \"REC_WORD\":\n",
    "            # get inter-retreival times since previous recall\n",
    "            evs['pirt'] = evs.groupby(['session', 'list'])['rectime'].diff().fillna(\n",
    "                evs['rectime'])\n",
    "            evs['repeat'] = evs.duplicated(subset=['session', 'list', 'item_name'])\n",
    "            evs['outpos'] = evs.groupby(['subject', 'session', 'list']).cumcount()\n",
    "            # only include recalls at least 1500 ms away and no repeats\n",
    "            evs = evs.query('pirt > 1500 and repeat == 0')\n",
    "            eeg = r.load_eeg(evs, \n",
    "                         rel_start=settings.rel_start, \n",
    "                        rel_stop=settings.rel_stop,\n",
    "                        scheme=scheme).to_ptsa()\n",
    "            # select relevant channels\n",
    "            eeg['time'] = eeg['time'] / 1000 # PTSA time scale is in seconds instead of ms\n",
    "            eeg = eeg.add_mirror_buffer(settings.buffer_time/1000)\n",
    "            eeg['time'] = eeg['time'] * 1000\n",
    "        else:\n",
    "            eeg = r.load_eeg(events=evs,\n",
    "                              rel_start=-settings.buffer_time+settings.rel_start,\n",
    "                              rel_stop=settings.buffer_time+settings.rel_stop,\n",
    "                              scheme=scheme).to_ptsa()\n",
    "\n",
    "        # centering signal within event\n",
    "        # reduce edge effects / ringing in later processing steps:\n",
    "        eeg = eeg.astype(float) - eeg.mean('time')\n",
    "        # filter out line noise at 60 Hz\n",
    "        eeg = ButterworthFilter(filt_type='stop', \n",
    "                                freq_range=[58, 62], \n",
    "                                order=4).filter(timeseries=eeg)\n",
    "        pows = MorletWaveletFilter(freqs=settings.freqs,\n",
    "                                   width=settings.width,\n",
    "                                   output='power',\n",
    "                                   cpus=4).filter(timeseries=eeg)\n",
    "        del eeg\n",
    "        #resample to resamplerate\n",
    "        print('resample rate', settings.resameplerate)\n",
    "        pows = xr.ufuncs.log10(pows)\n",
    "        pows = ResampleFilter(resamplerate=settings.resameplerate).filter(\n",
    "            timeseries=pows)\n",
    "        pows = pows.remove_buffer(settings.buffer_time / 1000)\n",
    "        if settings.type != \"COUNTDOWN_START\":\n",
    "            pows = pows.mean('time') #average over time\n",
    "        # reshape as events x features\n",
    "        pows = pows.stack(features=(\"channel\", \"frequency\"))\n",
    "        if 'stim_params' in pows.indexes['event'].names:\n",
    "            pows = pows.assign_coords(\n",
    "                {\"event\": pows.indexes['event'].droplevel('stim_params')}\n",
    "            )\n",
    "        pows = pows.assign_attrs(settings.__dict__)\n",
    "        pows.to_hdf(save_fp)\n",
    "        return pows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c335156-d11f-4e32-b1b9-0722a3ab5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = da.Settings()\n",
    "# freqs = np.unique(np.round(np.logspace(np.log10(1), np.log10(300), 17)))\n",
    "settings.freqs = np.logspace(np.log10(3),np.log10(180), 8)\n",
    "settings.width = 6\n",
    "settings.rel_start = 0\n",
    "settings.rel_stop = 10000\n",
    "settings.resameplerate = 1\n",
    "settings.experiment = 'catFR1'\n",
    "settings.type = 'COUNTDOWN_START'\n",
    "# settings.buffer_time = (settings.width / 2) * (1000 / min(settings.freqs))\n",
    "settings.buffer_time = 1000\n",
    "settings.Save(\"catFR1_countdown_preprocess.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d4b8a-7e5a-4b7c-9ea0-9ba99172c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = da.Settings()\n",
    "settings.width = 6\n",
    "settings.rel_start = 300\n",
    "settings.rel_stop = 1300\n",
    "settings.experiment = 'catFR1'\n",
    "settings.freqs = np.logspace(np.log10(3),np.log10(180), 8)\n",
    "settings.type = 'WORD'\n",
    "settings.buffer_time = (settings.width / 2) * (1000 / min(settings.freqs))\n",
    "settings.freqs = np.logspace(np.log10(3),np.log10(180), 8)\n",
    "settings.resameplerate = 500\n",
    "settings.Save(\"catFR1_encoding_preprocess.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890ea43-da0f-4c7d-8bd1-8bdfc0be71fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = da.Settings()\n",
    "# freqs = np.unique(np.round(np.logspace(np.log10(1), np.log10(300), 17)))\n",
    "settings.freqs = np.logspace(np.log10(3),np.log10(180), 8)\n",
    "settings.width = 6\n",
    "settings.experiment = 'catFR1'\n",
    "settings.resameplerate = 500\n",
    "settings.type = 'REC_WORD'\n",
    "settings.rel_start = -900\n",
    "settings.rel_stop = -100\n",
    "settings.buffer_time = 760\n",
    "settings.Save(\"catFR1_retrieval_preprocess.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb86bc-a4f9-402b-b75e-974d8ace5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = da.new_dask_client(\"class_preprocessing\",\n",
    "                            \"55GB\",\n",
    "                            max_n_jobs=10,\n",
    "                            log_directory='/scratch/djh/rsa_class/log_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acac821-13fe-4b24-9c58-adf748a26bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    compute_features, \n",
    "    list(exp_ix.itertuples()), \n",
    "    overwrite=True,\n",
    "    settings_path='/home1/djhalp/ieeg_rsa/catFR1_countdown_preprocess.pkl',\n",
    "    save_path='/scratch/djh/rsa_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d7700-7cb8-4c2b-bde9-7c380bc81f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da.filter_futures(futures, status='pending'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809fb92-4eeb-417f-af9a-cac511ec43ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait(futures)\n",
    "errors = da.get_exceptions(futures, range(len(futures)))\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d74ea4-334f-4553-a434-a3b5c0b4b44b",
   "metadata": {},
   "source": [
    "We got a couple errors but its not a huge deal, we'll just ignore these sessions for now. If we want to investigate the error though we can look at the traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8e84e-625d-403d-9c70-dcbdf4a53cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traceback.print_tb(errors.traceback_obj.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c1e3d-b2e7-4fa5-b938-f4a48372d6e0",
   "metadata": {},
   "source": [
    "Now we'll process the encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1a8d2-492c-437a-b2c4-14594ec23d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    compute_features, \n",
    "    list(exp_ix.itertuples()), \n",
    "    overwrite=False,\n",
    "    settings_path='/home1/djhalp/ieeg_rsa/catFR1_encoding_preprocess.pkl',\n",
    "    save_path='/scratch/djh/rsa_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9568e-f757-4bd2-80b2-d8c37a115d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da.filter_futures(futures, status='pending'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7846c3-b03e-401a-b7a0-b2fabf72acf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait(futures)\n",
    "errors = da.get_exceptions(futures, range(len(futures)))\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba6e56-ec79-4b67-8feb-834ed246ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    compute_features, \n",
    "    list(exp_ix.itertuples()), \n",
    "    overwrite=False,\n",
    "    settings_path='/home1/djhalp/ieeg_rsa/catFR1_retrieval_preprocess.pkl',\n",
    "    save_path='/scratch/djh/rsa_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b4236-61b8-4d8b-81f2-c7c2552ebc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da.filter_futures(futures, status='pending'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c943e-77b4-4bb2-9632-55f766dfe6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = da.get_exceptions(futures, range(len(futures)))\n",
    "errors['exception']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f172e8-5bcc-454c-9758-22b4c9755cd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d536f-63bb-4ece-ab86-5eec44fc6e9b",
   "metadata": {},
   "source": [
    "Now we have to compute the RSA. This basically involves loading the outputs of the `compute_features` function above and using the xarray `corr` function which will compute the correlation matrix between two data arrays and hold on to all the relevant information for us. There are two tricky things going on here. One is that we need to normalize the encoding and retrieval time features by the countdown features. we have a function called `normalize_features` to do that. We also need to change the names of the event information so that they don't match. If they do, the `corr` function will assume they are referring to the same informaiton and will not compute a correlation between them. In order to distinguish the item_name at retrieval and at encoding, we append the event `type` onto the name of each column. If we are computing the correlation between two events of the same `type` (e.g. each encoding event to other encoding events), we add a 2 on the end to distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47490b0e-5226-4d98-9d89-c913cc17fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = da.Settings()\n",
    "settings.experiment = \"catFR1\"\n",
    "settings.encoding_type = \"WORD\"\n",
    "settings.comparison_type = \"WORD\"\n",
    "settings.countdown_normalize = 1\n",
    "settings.Save(\"catFR1_encoding_rsa.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa43722-1d51-4da2-9c90-88a2d6019511",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.comparison_type = \"REC_WORD\"\n",
    "settings.Save(\"catFR1_retrieval_rsa.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d436f17-baa1-4696-826f-31230477b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(pows, save_path, countdown_normalize=True):\n",
    "    subject, session = pows.event.subject.values[0], pows.event.session.values[0]\n",
    "    if countdown_normalize:\n",
    "        countdown_fp = save_path + '/' + subject + '_' + str(session) + '_COUNTDOWN_START_feats.h5'\n",
    "        countdown_pows = TimeSeries.from_hdf(countdown_fp)\n",
    "        countdown_pows['samplerate'] = pows['samplerate']\n",
    "        pows = (pows - countdown_pows.mean(['event', 'time'])) / countdown_pows.std(['event', 'time']) \n",
    "    else:\n",
    "        pows = pows.reduce(func=sp.stats.zscore, dim='event', keep_attrs=True, ddof=1)\n",
    "    return pows\n",
    "\n",
    "def set_event_names(pows, period_type, col='event', copy=False):\n",
    "    if copy:\n",
    "        pows = pows.copy()\n",
    "    events_mi = pows[col].to_index()\n",
    "    events_mi = events_mi.rename(\n",
    "        [name+'_'+period_type for name in events_mi.names])\n",
    "    pows[col] = events_mi\n",
    "    pows = pows.rename({col: col+'_'+period_type})\n",
    "    return pows\n",
    "\n",
    "def compute_rsa(row, overwrite=False,\n",
    "                settings_path='/home1/djhalp/ieeg_rsa/catFR1_encoding_rsa.pkl', \n",
    "                save_path='/scratch/djh/rsa_class/'):\n",
    "    \"\"\"\n",
    "    Compute rsa between two periods.\n",
    "    \"\"\"\n",
    "    settings = da.Settings.Load(settings_path)\n",
    "    ix = cml.get_data_index()\n",
    "    print(\"Processing subject:\", row.subject, \"session:\", row.session)\n",
    "    save_fp = save_path + '/' + row.subject + '_' + str(row.session) + '_' + settings.encoding_type + '_' + settings.comparison_type + '_rsa.h5'\n",
    "    if (not os.path.exists(save_fp)) or overwrite:\n",
    "        # intialize data reader, load words events and buffered eeg epochs\n",
    "        encoding_fp = save_path + '/' + row.subject + '_' + str(row.session) + '_' + settings.encoding_type + '_feats.h5'\n",
    "        \n",
    "        #need to rename event index to keep track of things for correlation matrix\n",
    "        encoding_pows = TimeSeries.from_hdf(encoding_fp)\n",
    "#         print('enc_pows', encoding_pows)\n",
    "        encoding_pows = normalize_features(encoding_pows, save_path, countdown_normalize=settings.countdown_normalize)\n",
    "        if settings.comparison_type == settings.encoding_type:\n",
    "            comparison_pows = set_event_names(encoding_pows, settings.encoding_type+'2', col='event', copy=True)\n",
    "        else:\n",
    "            comparison_fp = save_path + '/' + row.subject + '_' + str(row.session) + '_' + settings.comparison_type + '_feats.h5'\n",
    "            comparison_pows = TimeSeries.from_hdf(comparison_fp)\n",
    "            comparison_pows = normalize_features(comparison_pows, save_path, countdown_normalize=settings.countdown_normalize)\n",
    "            comparison_pows = set_event_names(comparison_pows, settings.comparison_type, col='event')\n",
    "        encoding_pows = set_event_names(encoding_pows, settings.encoding_type, col='event')\n",
    "        \n",
    "        \n",
    "#         _cov_corr(encoding_pows, comparison_pows, dim='features', method=\"corr\")\n",
    "        \n",
    "        corr_arr = xr.corr(encoding_pows, comparison_pows, dim='features')\n",
    "        print('corr_arr', corr_arr.indexes)\n",
    "        corr_df = corr_arr.to_dataframe('corr').reset_index()\n",
    "        corr_df['corr_z'] = np.arctanh(corr_df['corr'])\n",
    "        corr_df.to_csv(save_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4627410-25ab-456e-ad05-1ece095cec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    compute_rsa, \n",
    "    list(exp_ix.itertuples()), \n",
    "    overwrite=False,\n",
    "    settings_path='/home1/djhalp/ieeg_rsa/catFR1_encoding_rsa.pkl',\n",
    "    save_path='/scratch/djh/rsa_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509172c1-f7f0-4763-a311-d8b2d8a1ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da.filter_futures(futures, status='pending'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1930bc7-8115-42c8-b25e-7b47cc5ebf3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = da.get_exceptions(futures, range(len(futures)))\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8bb42-c480-4c69-baa3-55ab8009d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(\n",
    "    compute_rsa, \n",
    "    list(exp_ix.itertuples()), \n",
    "    overwrite=False,\n",
    "    settings_path='/home1/djhalp/ieeg_rsa/catFR1_retrieval_rsa.pkl',\n",
    "    save_path='/scratch/djh/rsa_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a176a17-7d72-4290-92a0-2b6d10c67876",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da.filter_futures(futures, status='pending'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c227f22-7c04-4bc6-835f-40b9ad1b6842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = da.get_exceptions(futures, range(len(futures)))\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b1bd6-ac24-4921-a3db-0b62b26f8517",
   "metadata": {},
   "source": [
    "Finally we just need to aggregate all the RSA matrices together into one giant dataframe for future analysis. For the encoding-to-encoding RSA, we'll also cut things down a bit by enforcing that the `_WORD` events come before `_WORD2`. This is fine since the full correlation matrix is symmetric so we're just taking the lower triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d4fa9-217f-41d5-ad80-5b874dd3a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/scratch/djh/rsa_class/'\n",
    "encoding_type = \"WORD\"\n",
    "comparison_type = \"WORD\"\n",
    "experiment = 'catFR1'\n",
    "ix = cml.get_data_index()\n",
    "sub_ix = ix.query('experiment == @experiment and subject == @subs')\n",
    "rsa_dfs = []\n",
    "\n",
    "for _, row in sub_ix.iterrows():\n",
    "    try:\n",
    "        rsa_fp = save_path + str(row['subject']) + '_' + str(row['session']) + '_' + encoding_type + '_' + comparison_type + '_rsa.h5'\n",
    "        rsa_df = pd.read_csv(rsa_fp)\n",
    "        #only need lower triangle\n",
    "        rsa_df = rsa_df.query('((list_WORD2 > list_WORD) or ' +\n",
    "                              '((list_WORD2 == list_WORD) and ' +\n",
    "                              '(serialpos_WORD2 > serialpos_WORD)))'\n",
    "                             )\n",
    "\n",
    "        rsa_dfs.append(rsa_df)\n",
    "    except:\n",
    "        continue\n",
    "raw_WORD_rsa_df = pd.concat(rsa_dfs)\n",
    "raw_WORD_rsa_df.to_csv(save_path + 'raw_WORD_rsa_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96444903-f88e-4829-919d-06a0cc5eb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_WORD_rsa_df['corr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970f61f-1432-4d24-8ca4-2cfd4616903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/scratch/djh/rsa_class/'\n",
    "encoding_type = \"WORD\"\n",
    "comparison_type = \"REC_WORD\"\n",
    "experiment = 'catFR1'\n",
    "ix = cml.get_data_index()\n",
    "sub_ix = ix.query('experiment == @experiment and subject == @subs')\n",
    "rsa_dfs = []\n",
    "\n",
    "for _, row in sub_ix.iterrows():\n",
    "    try:\n",
    "        rsa_fp = save_path + str(row['subject']) + '_' + str(row['session']) + '_' + encoding_type + '_' + comparison_type + '_rsa.h5'\n",
    "        rsa_df = pd.read_csv(rsa_fp)\n",
    "\n",
    "        rsa_dfs.append(rsa_df)\n",
    "    except:\n",
    "        continue\n",
    "raw_REC_WORD_rsa_df = pd.concat(rsa_dfs)\n",
    "raw_REC_WORD_rsa_df.to_csv(save_path + 'raw_REC_WORD_rsa_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cc3d8-1d2a-4656-ab45-679e3e91e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_REC_WORD_rsa_df['corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b7560-f450-43dd-aba9-7f0c73bbf9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_REC_WORD_rsa_df['corr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8509ac-b5fe-4e83-b77d-d7f74a71da7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
