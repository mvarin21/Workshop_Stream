{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1886ef-a133-4036-aa53-41446a63c926",
   "metadata": {},
   "source": [
    "# Assignment 10: Multivariate and Machine Learning Analysis for Intracranial EEG Data\n",
    "Please submit this assignment to Canvas as a jupyter notebook (.ipynb).  The assignment will have you compare the ability of different machine learning techniques to classify neural memory states, as well as the examine the effects of normalizing the EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26358fe1-5ea7-4d9f-b982-6e449bc303ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmlreaders as cml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20508d1-7194-44e0-ad4b-457db03ddf71",
   "metadata": {},
   "source": [
    "## Assignment Overview\n",
    "\n",
    "In this assignment you will investigate how different penalization schemes and z-scoring features can produce different behaviors in the classifier. Recall that the objective function for penalized logistic regression is: \n",
    "\n",
    "$l(\\beta) = \\Sigma_{i=1}^N{y_i log p_i + (1 − y_i) log(1 − p_i)} + \\frac{\\alpha}{2} r||\\beta||_2^2 + \\alpha(1 − r)||\\beta||_1$\n",
    "\n",
    "where, $\\alpha = 1/C$ is the penalty parameter, r is the contribution of L2 penalty, and 1 − r is the contribution of L1 penalty. When r = 1, we have a strictly L2 penalized logistic regression. When r = 0, we have a strictly L1 penalized regression (a.k.a. Lasso). When 0 < r < 1, we have a mixture of both L1 and L2, which is called elastic net. In this part, you will compare the performances of different penalization schemes: strictly L2, strictly L1, and elastic net with r = 0.5.\n",
    "\n",
    "Again, use data from the following 20 FR1/catFR1 subjects in the intracranial EEG (iEEG) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f541c67-d63b-4cdf-b4f2-c560e9540dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = ['R1380D', 'R1380D', 'R1111M', 'R1332M', 'R1377M', \n",
    "        'R1065J', 'R1385E', 'R1189M', 'R1108J', 'R1390M', \n",
    "        'R1236J', 'R1391T', 'R1401J', 'R1361C', 'R1060M', \n",
    "        'R1350D', 'R1378T', 'R1375C', 'R1383J', 'R1354E', \n",
    "        'R1292E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c156792c-3c28-449d-a75b-6ffcb18d1d98",
   "metadata": {},
   "source": [
    "For each of these subjects, use the following processing steps:\n",
    "* Load EEG with CMLReader.load_eeg from a bipolar montage loaded using CMLReader.load('pairs').\n",
    "* Apply a Butterworth notch filter around 60 Hz (freqs = [58 62]) when extracting the voltage.\n",
    "* Calculate power at the above frequencies with a Morlet wavelet with wavenumber (keyword “width”) of 6 for each encoding event (from time 0 until 1.6 seconds after the encoding event onset) using a 1 second buffer.\n",
    "* For each frequency, channel, and encoding event, average the power over the entire 1600 ms encoding period (but not over the buffer period!)\n",
    "* Log-transform the average encoding power values as in the final step of the previous problem.\n",
    "* In some cases you may notice artifacts in the data that manifest in power values of zero. These would produce problems in the transformation and classification, so please exclude any events with this issue from all analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3123-e430-4e0f-9468-75f34d653765",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1\n",
    "1) Repeat the nested cross-validation procedure from the previous assignment, now using z-scored features.  Do so separately for L2, L1, and elastic net. \n",
    "\n",
    "* You should again use sklearn’s linear_model.LogisticRegression class for your classifier, appropriately selecting the classifier hyperparameters to obtain the L1 and elastic net regularization schemes.\n",
    "\n",
    "2) Compare the performances (AUCs) across these three schemes using a barplot or whatever you see fit, including some visualization of variability in the outcomes for these methods. Does one scheme do better than the others?\n",
    "\n",
    "* Keep in mind that the sklearn LogisticRegression parameter `C` is an inverse regularization strength, meaning the regularization strength is equal to $\\alpha$ = 1/C. So higher `C` means lower regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81b4f35-00ef-4fd6-abba-e28b659ce7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e58c1d33-9c2c-4e75-9989-4813eb7c78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.2\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c63d19-1ebe-4b7b-afc1-1bf32a120872",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "1) Generate a plot for each of the first three subjects containing three histograms (one for each penalization scheme) of the model coefficients.\n",
    "* Use the *model.coef_* attribute (*model* is your classifier object) to investigate the learned coefficients of the classifier for each subject. You can pool classifier weights across all outer cross-validation folds. \n",
    "* Use the *alpha* parameter of the plt.hist function to ensure the histograms do not cover each other up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05388b55-764c-4588-9496-915c5f0c5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2.1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3827e6-494c-4b25-9cea-c81f1d4eefa5",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "It has been shown that L1 penalization introduces sparsity to classifier weights, i.e. some of the β’s in the model will be zero with L1. \n",
    "\n",
    "1) For each subject, report the proportion of non-zero β’s for that subject’s classifier weights pooled across outer cross-validation folds separately for these three schemes. Plot a histogram of these subject proportions for each penalization scheme. \n",
    "\n",
    "2) What can you say about the proportions of non-zero β’s across the three penalization schemes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc1968e-49f4-4dd3-b5a1-409d3c709d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400bd3d-08ff-4b60-838a-88711db58994",
   "metadata": {},
   "source": [
    "Question 3.2\n",
    "\n",
    "**YOUR CODE HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d6833-b600-48b8-a00f-51eb4f1ee709",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "1) Test whether z-scoring improves classifier performance by repeating the analysis from question but without z-scored features for L2, L1, and elastic net.\n",
    "\n",
    "2) Which is better, raw features or z-scored features?  Give an intuitive explanation as to why one is better than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5504a107-617b-4f94-8513-b597433c97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4.1\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659653d9-479a-4d0b-a92b-0bebfadf5145",
   "metadata": {},
   "source": [
    "Question 4.2\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f833b-2ec7-4137-a2a0-930565429b7c",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "So far, you've used a mean nested CV score to compare penalization schemes and to compare z-scored features to raw features. \n",
    "\n",
    "1) What can we conclude about the generalization of these comparisons? Are the improvements you found between these methods biased or unbiased in the sense of overfitting? In other words, if you tested whichever methods among these tested methods that you found achieved the optimal score in a fresh held-out data set, would the method be expected to achieve the same expected performance (assume we had a large enough sample of subjects to ignore subject-level variability)? What would be one scheme you could use to obtain an unbiased estimator of the population-level (as opposed to the individual subject-level) hold-out performance of your chosen optimal methods in new data? \n",
    "\n",
    "2) What about a scheme for an unbiased estimate of the performance of these methods at the individual subject level? In other words, if we wanted to ask \"which penalization method or z-scoring approach is best for each subject separately?\" and then evaluate the performance of the best method for that subject at the individual level, how could we do it in an unbiased manner (without \"cheating\")? Think about the methods you've used so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418ce88-3ba0-4129-a0e9-01c9e4ed0ccc",
   "metadata": {},
   "source": [
    "Question 5.1\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06a28b-b86f-4c45-9e26-cb7f35f77aa4",
   "metadata": {},
   "source": [
    "Question 5.2\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bids",
   "language": "python",
   "name": "bids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
