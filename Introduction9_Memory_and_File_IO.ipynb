{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a147596-1c32-4263-ae50-56f4c1692c59",
   "metadata": {},
   "source": [
    "## Memory Utilization (the computer kind)\n",
    "\n",
    "While scaling up code for big data analyses, performance and scaling requirements make it important to gain the skills to predict RAM requirements and monitor RAM consumption in order to maximally utilize resources.  This also helps to identify areas of analyses that need modification in order to run within the physical constraints of a particular system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c18eda5d-3d13-450e-9852-4451a4d66f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import sys\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78329299-aeb3-42d9-b12b-5442eb65e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = np.zeros((1024, 1024, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd7896a-1f7f-46c3-8508-02756d3db6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions\n",
    "big_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72301812-e5ea-49bf-804b-9a9f3e03a787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data being stored\n",
    "big_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aecb339-4bdc-4c1f-bc4b-15be9e89392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storage per element\n",
    "big_array.dtype.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcc32ee-b692-4b7d-b1b6-7ad959f4c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134217728"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total element count: N_x * N_y * N_z\n",
    "np.prod(big_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e72cff1-eddc-4778-b771-6f32be4f327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073741824"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total storage\n",
    "np.prod(big_array.shape) * big_array.dtype.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "796df22c-cb21-44df-b79e-94944cd1865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Human readable:\n",
    "def PrintArraySize(a):\n",
    "  count = np.prod(a.shape)\n",
    "  elem_size = a.dtype.itemsize\n",
    "  print(f'{count*elem_size/1024**3} GB')\n",
    "\n",
    "PrintArraySize(big_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152f3e86-4b12-4b60-959d-ae75edf78a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=134775570432, available=112133500928, percent=16.8, used=18995654656, free=16937414656, active=73788833792, inactive=40268271616, buffers=0, cached=98842501120, shared=3005235200, slab=2562609152)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87816493-5dce-4eb7-a496-ed8fac7541e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psutil.Process(pid=99261, name='python', status='running', started='12:41:32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86fd8290-5fa5-434a-8b6b-d55c1d1625ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pmem(rss=76824576, vms=2089955328, shared=14094336, text=3342336, lib=0, data=1900896256, dirty=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rss is \"Resident Set Size\",\n",
    "# vms is \"Virtual Memory Size\" which includes other aspects of memory such\n",
    "# as memory swapped to disk (not in use on Rhino) and that might be\n",
    "# copy-on-write shared, such as shared library memory that typically won't\n",
    "# count against usage limits.\n",
    "# These values right here are low because of Linux \"over-commit\" features.\n",
    "# It will only assign real memory once it's used, not when it's reserved.\n",
    "psutil.Process(os.getpid()).memory_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329b1ef-4fcc-44e6-a42b-cc2152273fa4",
   "metadata": {},
   "source": [
    "Checking your active processes. ssh into rhino (or open a terminal), and run:\n",
    "```squeue -u your_username```\n",
    "\n",
    "Your JupyterLab server will look like \"spawner-\", and will have a node associated.  Your cluster jobs will have names based on the functions you launched.  You can connect to the node for an active job with ssh like:\n",
    "```ssh node42```\n",
    "\n",
    "Then you can run the program \"top\" where shift-P sorts processes by processor load, and shift-M sorts processes by memory load.  Sometimes this is helpful for quickly seeing the load of a running process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21dda3ba-5d2a-4de7-93c1-51809c6400c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's actually use the memory!  We'll assign 1 to every entry.\n",
    "big_array[:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf6bd01-010b-4b4b-86f8-57a04d3a8a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pmem(rss=1151201280, vms=2089955328, shared=14270464, text=3342336, lib=0, data=1900896256, dirty=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suddenly Linux recognizes that this is real memory in real use,\n",
    "# and gives it physical storage!\n",
    "psutil.Process(os.getpid()).memory_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4e5b401-8a7b-46a5-80cf-a250d39ed520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0721473693847656"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.Process(os.getpid()).memory_info().rss / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fac3cd81-97d2-4743-8b20-db77c5f16081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07214736938476562"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean-up usage.  Note, this only sometimes works right away!\n",
    "big_array = None\n",
    "psutil.Process(os.getpid()).memory_info().rss / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fef3891c-ee33-43d6-9c4d-deb6fdea8a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07846832275390625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_aray = None\n",
    "# If you need a stronger guarantee of clean-up (rarely needed),\n",
    "# you can try calling the garbage collector manually\n",
    "gc.collect()\n",
    "psutil.Process(os.getpid()).memory_info().rss / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25fbbc91-6973-4791-bd0e-48ecf26dd720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0783843994140625\n",
      "0.07860946655273438\n"
     ]
    }
   ],
   "source": [
    "def WorkFunction():\n",
    "  big_array = np.zeros((1024, 1024, 128))\n",
    "  big_array[:] = 1\n",
    "  print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)\n",
    "\n",
    "WorkFunction()\n",
    "# Variables are cleaned up when the function returns!\n",
    "print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a44a69-c1ad-4aac-ac17-aa6974c73ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0785980224609375\n"
     ]
    }
   ],
   "source": [
    "# It's easy to build up memory utilization as you keep making modified copies.\n",
    "big_array = np.zeros((1024, 1024, 128))\n",
    "big_array[:] = 1\n",
    "big_array2 = 2*big_array\n",
    "print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8ebfa5e-f4d2-4b20-9669-32b780fe0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This manually removes variables, cleans up like assigning to None except\n",
    "# the variable has no definition anymore.\n",
    "del big_array\n",
    "del big_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8abf4a83-41b6-4413-bb41-f559c8f5a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0786323547363281\n"
     ]
    }
   ],
   "source": [
    "# Numpy arrays are more performant modifying in place.\n",
    "big_array = np.zeros((1024, 1024, 128))\n",
    "big_array[:] = 1\n",
    "big_array *= 2\n",
    "print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c91adb3b-4eae-4770-9d80-e080aa362def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.079498291015625\n"
     ]
    }
   ],
   "source": [
    "# Dimensionally reduced data is miniscule:\n",
    "big_array = np.zeros((1024, 1024, 128))\n",
    "big_array[:] = 1\n",
    "big_array_mean = np.mean(big_array, axis=0)\n",
    "print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6a84407-669e-4354-9702-20454b07c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del big_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abeffe84-4b40-4e97-936e-9c3c72f0d3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0805892944335938\n",
      "0.08058547973632812\n"
     ]
    }
   ],
   "source": [
    "# Smart approach!\n",
    "def MakeReducedData():\n",
    "  big_array = np.zeros((1024, 1024, 128))\n",
    "  big_array[:] = 1\n",
    "  big_array_mean = np.mean(big_array, axis=0)\n",
    "  print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)\n",
    "  return big_array_mean\n",
    "\n",
    "big_array_mean = MakeReducedData()\n",
    "print(psutil.Process(os.getpid()).memory_info().rss / 1024**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da365d-2514-4f8a-bab2-042fb7d08773",
   "metadata": {},
   "source": [
    "## File Input/Output (IO)\n",
    "\n",
    "Continuing on in Big Data analyses will give you an increased need to think carefully about file IO, as you migrate from using premade data to being a generator of data.\n",
    "\n",
    "### Temporary / Intermediate data\n",
    "\n",
    "This kind of data is transient, used in the middle of a calculation for storing a result for minutes, hours, or maybe up to a couple months.  It is data that typically does not need to be backed up, and where you are not worried about whether or not it can be accessed years later, or work on new environments or new computers or even on anyone else's computer or language.  You just need it to \"work\" cleanly and simply for short term work, usually to avoid recalculating things.\n",
    "\n",
    "Good examples of this in Python are pickle and numpy saved files.  Pickle is a \"do not share it\" data format, because there are security considerations where loading pickled data can actually execute code in the file.  But since there is little chance of you hacking yourself, you can gain the advantages of quickly streaming to disk arbitrary Python objects and reloading them.  Pickled data is NOT compatible if, for example, you save data for an object of a class type, and then change the class!  The same type needs to be available when you reload.  This means it will often stop working even on standard types or common library types if you upgrade to a new version of Python or new environment.  Hence, it is a powerful and useful temporary local-use format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67dabd8a-5544-4703-bd22-4a1d6cae852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "d = {'Bob': 34, 'Alice': 43, 'Joe': 25, 'Susan': 36}\n",
    "with open('my_dictionary.pkl', 'wb') as fw:\n",
    "  pickle.dump(d, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6046f96c-60b3-4ab8-a3b6-bc23b5ebcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bob': 34, 'Alice': 43, 'Joe': 25, 'Susan': 36}\n"
     ]
    }
   ],
   "source": [
    "with open('my_dictionary.pkl', 'rb') as fr:\n",
    "  d2 = pickle.load(fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a45e3f-f0ce-4c63-9077-8ac9c3702f9a",
   "metadata": {},
   "source": [
    "Saving with numpy, such as np.save or np.savez is similar, as some things you might save with numpy are actually pickled to do it!  Pure numerical data saved with numpy has slightly longer longevity, and non-pickled data saved with numpy can be shared, but it is probably not a format to trust for very long term storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f95f5bad-6a15-4744-b604-51103d32ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "262272"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((1024, 32))\n",
    "print(np.prod(a.shape)*a.dtype.itemsize)\n",
    "np.save('my_array.npy', a)\n",
    "os.path.getsize('my_array.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49eb14-ab20-45d4-969d-cf5986787cff",
   "metadata": {},
   "source": [
    "Notice numpy stores binary data compactly!  This is an asset for large data.\n",
    "\n",
    "### Long term archival of data\n",
    "\n",
    "If your data is small dimensionally reduced data, however, other formats like csv (comma-separated values) can be very convenient for long term archival (decades through human lifetime).  This matters a lot for valuable data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fae4177e-04f2-4099-b3c9-21e886616634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135169"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(a).to_csv('my_array.csv')\n",
    "os.path.getsize('my_array.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0046502-5292-4947-b6ec-a699b5b715b9",
   "metadata": {},
   "source": [
    "Here csv looks smaller!  But that's deceptive, because we're actually storing \"1, 1, 1, 1, 1, ...\" which is very compact because we used all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09037b13-eb35-4825-b655-a36f04d1ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "262272"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((1024, 32))\n",
    "print(np.prod(a.shape)*a.dtype.itemsize)\n",
    "np.save('my_array2.npy', a)\n",
    "os.path.getsize('my_array2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da65b737-7d61-4aa8-aa10-a784bbe60bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635236"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(a).to_csv('my_array2.csv')\n",
    "os.path.getsize('my_array2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70be5247-a036-476e-9a59-60d5b81bc110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\n",
      "\n",
      "0,0.739889406208754,0.2827046585389744,0.5594041053106992,0.5633814456955742,0.2552310893292975,0.622916572914727,0.7062238681696796,0.6854959592756991,0.05114680974080621,0.5794636349889507,0.39137033965991064,0.7190044458551405,0.8577175896018705,0.17390413774348434,0.9599656980161152,0.16408806183128533,0.6129906461368634,0.1570640515473538,0.4618601748807176,0.7720280759890569,0.23839910442168866,0.3550156568848738,0.8167389221351987,0.6049325039872016,0.7643235202997138,0.8579450885132974,0.18124433594727918,0.9737158705078566,0.025460105758991824,0.8850167581631706,0.6784267570443804,0.45367117021300396\n",
      "\n",
      "1,0.2918858553351016,0.9355939157922352,0.1945736169588289,0.6453342152398456,0.3661013387218227,0.21553416570966366,0.9736155533078619,0.5522047771507568,0.20369459218080765,0.9814204594871014,0.3867461700787206,0.9699237534278549,0.8320965570814466,0.6261214497253011,0.3247173015409378,0.1373044136552175,0.33884331114953936,0.5379205490815059,0.318108531621233,0.8636968194106976,0.07442081796082367,0.2617561077809808,0.21916676865543328,0.8220133241389198,0.42099261561922374,0.19229729853400646,0.46671351784197757,0.08395322337970501,0.2227256925785973,0.6349260108754822,0.3045969336723304,0.5330913212726426\n",
      "\n",
      "2,0.7037167853556018,0.6408797034628471,0.05808933647209569,0.8612941388583619,0.9542446358334924,0.2220072062155255,0.013014413136278935,0.3374482917061461,0.7385078434977052,0.3180323020964857,0.9714602085167261,0.07923211885840042,0.2983643350669306,0.17324612970972753,0.7885188863799542,0.4619994188916251,0.5605163047327694,0.5163987754749603,0.5503550307214616,0.760249983453685,0.9525704097589452,0.7887848478875155,0.35514832795029383,0.7347314977864773,0.22300203795393148,0.38876061297044406,0.3289035876094689,0.10409681057655173,0.27503665452792303,0.5100271209631121,0.5426194704726288,0.33304652610966656\n",
      "\n",
      "3,0.40498492764736904,0.2950661828722715,0.020534712243901687,0.7602350022006181,0.40057094568732055,0.7030627351600903,0.5686639226605457,0.9273711285768504,0.5818827644859765,0.1111209162122988,0.48270584378924053,0.14505094104216487,0.0650221941178758,0.3017490346785827,0.23322539064999326,0.7354037803434086,0.6056414523620925,0.04862567826594144,0.38537621789710497,0.017622088477129316,0.40941134863216067,0.1514320106710807,0.28285721987594437,0.10630114815266278,0.19442509617770443,0.8832351502314048,0.016716474589478558,0.8515107717558758,0.2656639280671741,0.16505836821536535,0.774980246077664,0.307176855021318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the first 5 lines of the file the manual way:\n",
    "with open('my_array2.csv', 'r') as fr:\n",
    "  lines = fr.readlines()\n",
    "  print('\\n'.join(lines[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3471ffa6-117f-4331-bfca-c7d8da1db660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631139"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maybe we just wanted the data, and not the headers and indices...\n",
    "pd.DataFrame(a).to_csv('my_array3.csv', header=None, index=None)\n",
    "os.path.getsize('my_array3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3365a23c-6d78-40ea-8831-674243f56b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.739889406208754,0.2827046585389744,0.5594041053106992,0.5633814456955742,0.2552310893292975,0.622916572914727,0.7062238681696796,0.6854959592756991,0.05114680974080621,0.5794636349889507,0.39137033965991064,0.7190044458551405,0.8577175896018705,0.17390413774348434,0.9599656980161152,0.16408806183128533,0.6129906461368634,0.1570640515473538,0.4618601748807176,0.7720280759890569,0.23839910442168866,0.3550156568848738,0.8167389221351987,0.6049325039872016,0.7643235202997138,0.8579450885132974,0.18124433594727918,0.9737158705078566,0.025460105758991824,0.8850167581631706,0.6784267570443804,0.45367117021300396\n",
      "\n",
      "0.2918858553351016,0.9355939157922352,0.1945736169588289,0.6453342152398456,0.3661013387218227,0.21553416570966366,0.9736155533078619,0.5522047771507568,0.20369459218080765,0.9814204594871014,0.3867461700787206,0.9699237534278549,0.8320965570814466,0.6261214497253011,0.3247173015409378,0.1373044136552175,0.33884331114953936,0.5379205490815059,0.318108531621233,0.8636968194106976,0.07442081796082367,0.2617561077809808,0.21916676865543328,0.8220133241389198,0.42099261561922374,0.19229729853400646,0.46671351784197757,0.08395322337970501,0.2227256925785973,0.6349260108754822,0.3045969336723304,0.5330913212726426\n",
      "\n",
      "0.7037167853556018,0.6408797034628471,0.05808933647209569,0.8612941388583619,0.9542446358334924,0.2220072062155255,0.013014413136278935,0.3374482917061461,0.7385078434977052,0.3180323020964857,0.9714602085167261,0.07923211885840042,0.2983643350669306,0.17324612970972753,0.7885188863799542,0.4619994188916251,0.5605163047327694,0.5163987754749603,0.5503550307214616,0.760249983453685,0.9525704097589452,0.7887848478875155,0.35514832795029383,0.7347314977864773,0.22300203795393148,0.38876061297044406,0.3289035876094689,0.10409681057655173,0.27503665452792303,0.5100271209631121,0.5426194704726288,0.33304652610966656\n",
      "\n",
      "0.40498492764736904,0.2950661828722715,0.020534712243901687,0.7602350022006181,0.40057094568732055,0.7030627351600903,0.5686639226605457,0.9273711285768504,0.5818827644859765,0.1111209162122988,0.48270584378924053,0.14505094104216487,0.0650221941178758,0.3017490346785827,0.23322539064999326,0.7354037803434086,0.6056414523620925,0.04862567826594144,0.38537621789710497,0.017622088477129316,0.40941134863216067,0.1514320106710807,0.28285721987594437,0.10630114815266278,0.19442509617770443,0.8832351502314048,0.016716474589478558,0.8515107717558758,0.2656639280671741,0.16505836821536535,0.774980246077664,0.307176855021318\n",
      "\n",
      "0.21739567409065408,0.7430259044802644,0.24450077508860024,0.5317803140339565,0.4132977028646234,0.09530670386889806,0.9705618646160519,0.06155973913780233,0.021830277692082123,0.7163493557950115,0.6000559296343945,0.20892203977603074,0.02022059323376546,0.05618332131771708,0.015956371378226475,0.6849166031054765,0.28391710901218403,0.2581424473291425,0.8462397937910087,0.14705846018021684,0.6264238929612642,0.6746380715990667,0.5267742277054313,0.3443521204991976,0.938434601343256,0.8667876299365597,0.3459883028215128,0.27369573928713653,0.9243737779484323,0.4569842360683477,0.4562408004179088,0.5651499866689523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at the first 5 lines of the file the manual way:\n",
    "with open('my_array3.csv', 'r') as fr:\n",
    "  lines = fr.readlines()\n",
    "  print('\\n'.join(lines[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b2600-19f4-4bc2-8c21-3a51fa83263f",
   "metadata": {},
   "source": [
    "The json format is another text format for data which retains human-readable properties, and can be expected to have long term archival properties.  As a text format it is easy to work with but often not compact for numerical data, so it is an appropriate store for dimensionally reduced results and smaller data that you want to preserve for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11189958-88e5-4272-8a60-d2985a0f88af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "d = {'Bob': 34, 'Alice': 43, 'Joe': 25, 'Susan': 36, 'TheSmithBrothers': [29, 31]}\n",
    "with open('the_ages.json', 'w') as fw:\n",
    "  json.dump(d, fw)\n",
    "os.path.getsize('the_ages.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "182ae560-5d1f-497e-ae5c-9279a6d6a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bob': 34, 'Alice': 43, 'Joe': 25, 'Susan': 36, 'TheSmithBrothers': [29, 31]}\n"
     ]
    }
   ],
   "source": [
    "with open('the_ages.json', 'r') as fr:\n",
    "  d2 = json.load(fr)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c414749-75f0-4121-a69d-8cbb8052616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Bob\": 34, \"Alice\": 43, \"Joe\": 25, \"Susan\": 36, \"TheSmithBrothers\": [29, 31]}\n"
     ]
    }
   ],
   "source": [
    "# Let's see what we stored.\n",
    "with open('the_ages.json', 'r') as fr:\n",
    "  lines = fr.readlines()\n",
    "  print('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cc691-57bd-4742-a4ab-c48bfebabbc7",
   "metadata": {},
   "source": [
    "The json format stores as human readable text, and in fact looks a lot like Python code!  This is a very future-save archival format for data that fits into the supportd types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d6821-90db-4a81-b40f-df473a911a99",
   "metadata": {},
   "source": [
    "For long term compact archiving of large binary data, you will want to do some reading for the particular type of data you are trying to store, and choose a format that you estimate will work well for this and retain long support.  There is no one answer for this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_311",
   "language": "python",
   "name": "workshop_311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
